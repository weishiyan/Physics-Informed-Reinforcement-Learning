{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time \n",
    "from pyDOE import lhs\n",
    "from datetime import datetime\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy/Struct gives Lua-like struct object with 0 defaults\n",
    "class dummy(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct(dummy):\n",
    "    def __getattribute__(self, key):\n",
    "        if key == '__dict__':\n",
    "            return super(dummy, self).__getattribute__('__dict__')\n",
    "        return self.__dict__.get(key, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMEGA = 1\n",
    "THETA_0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size on the solution u\n",
    "N_u = 500\n",
    "# Collocation points size, where we’ll check for f = 0\n",
    "N_f = 10000\n",
    "\n",
    "\n",
    "# DeepNN topology (1-sized input [t], 8 hidden layer of 20-width, 1-sized output [u]\n",
    "list_of_layers = []\n",
    "# [1, 80x8, 1]\n",
    "max_node = 80  # List size\n",
    "num_list = 1  # number of layer list\n",
    "num_hidden = 3  # number of hidden layers\n",
    "interval = max_node/num_list\n",
    "\n",
    "for i in range(num_list):\n",
    "    temp_list = [1]\n",
    "    # Number of hidden layers\n",
    "    for j in range(num_hidden):\n",
    "        temp_list.append(max_node)\n",
    "    temp_list.append(1)\n",
    "    max_node -= interval\n",
    "    list_of_layers.append(temp_list)\n",
    "\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "tf_epochs = 5000\n",
    "lr = 0.0001\n",
    "beta1=0.9\n",
    "eps = 0.1\n",
    "noise = 0.01\n",
    "tf_optimizer = tf.keras.optimizers.Adam(learning_rate=lr,\n",
    "                                        beta_1=beta1,\n",
    "                                        epsilon=eps)\n",
    "\n",
    "# # Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "# nt_epochs = 2000\n",
    "# nt_config = Struct()\n",
    "# nt_config.learningRate = 0.8\n",
    "# nt_config.maxIter = nt_epochs\n",
    "# nt_config.nCorrection = 50\n",
    "# nt_config.tolFun = 1.0 * np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(N_u, N_f, noise=0.0):\n",
    "    # Domain bounds (lowerbounds upperbounds) [x, t], which are here ([-1.0, 0.0] and [1.0, 1.0])\n",
    "#     lb = 0\n",
    "#     ub = num_pi *np.pi\n",
    "#     # Generating the t points for f with a N_f size\n",
    "#     # We pointwise add and multiply to spread the LHS over the domain\n",
    "#     X_f = lb + (ub - lb) * lhs(1, N_f)\n",
    "#     Exact_u = THETA_0*np.cos(OMEGA*X_f)\n",
    "#     X_u_train = lb + (ub - lb) * lhs(1, N_f)\n",
    "#     u_train = THETA_0*np.cos(OMEGA*X_u_train) + noise*np.random.randn(N_f, 1)\n",
    "    \n",
    "    npz = np.load(\"Deep_Deterministic_Policy_Gradients_notebooks/data/single_action_0.5_pendulum_data_L100.npz\", allow_pickle=True)\n",
    "    # Loading data and ordering it to N x 1 array\n",
    "    states = npz[\"states\"]\n",
    "    theta = states[:,1][:, None] - np.pi\n",
    "    times = npz[\"time\"][:,None]\n",
    "    \n",
    "#     # Trying something out with more dense x-axis\n",
    "#     list_size = theta.shape[0]\n",
    "#     steps = 0.01\n",
    "#     times = [x*steps for x in range(list_size)]\n",
    "#     times = np.array(times) \n",
    "#     times = times[:, None]\n",
    "    \n",
    "    # Adding noise\n",
    "    mu, sigma = 0, noise\n",
    "    # give same shape as data\n",
    "    random_noise = np.random.normal(mu, sigma, [len(theta)])\n",
    "    theta = theta + random_noise[:, None]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Reduce data set size for testing\n",
    "    theta_train = theta[:N_u]\n",
    "    time_train = times[:N_u]\n",
    "    \n",
    "    lb = times.min(axis=0)\n",
    "    ub = times.max(axis=0)\n",
    "#     time_train = lb + (ub - lb) * lhs(1, N_u)\n",
    "    \n",
    "    return times, theta, time_train, theta_train, lb, ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self, frequency=10):\n",
    "        print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "        print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "        print(\"GPU-accerelated: {}\".format(tf.test.is_gpu_available()))\n",
    "\n",
    "        self.start_time = time.time()\n",
    "        self.frequency = frequency\n",
    "\n",
    "    def __get_elapsed(self):\n",
    "        return datetime.fromtimestamp(time.time() -\n",
    "                                      self.start_time).strftime(\"%M:%S\")\n",
    "\n",
    "    def __get_error_u(self):\n",
    "        return self.error_fn()\n",
    "    \n",
    "    def log_time(self):\n",
    "        return time.time() - self.start_time\n",
    "#         return datetime.fromtimestamp(time.time() -\n",
    "#                                       self.start_time)\n",
    "    \n",
    "    def set_error_fn(self, error_fn):\n",
    "        self.error_fn = error_fn\n",
    "\n",
    "    def log_train_start(self, model):\n",
    "        print(\"\\nTraining started\")\n",
    "        print(\"================\")\n",
    "        self.model = model\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def log_train_epoch(self, epoch, loss, custom=\"\", is_iter=False):\n",
    "        if epoch % self.frequency == 0:\n",
    "            print(\n",
    "                f\"{'nt_epoch' if is_iter else 'tf_epoch'} = {epoch:6d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e}  error = {self.__get_error_u():.4e}  \"\n",
    "                + custom)\n",
    "\n",
    "    def log_train_opt(self, name):\n",
    "        # print(f\"tf_epoch =      0  elapsed = 00:00  loss = 2.7391e-01  error = 9.0843e-01\")\n",
    "        print(f\"—— Starting {name} optimization ——\")\n",
    "\n",
    "    def log_train_end(self, epoch, custom=\"\"):\n",
    "        print(\"==================\")\n",
    "        print(\n",
    "            f\"Training finished (epoch {epoch}): duration = {self.__get_elapsed()}  error = {self.__get_error_u():.4e}  \"\n",
    "            + custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time tracking functions\n",
    "global_time_list = []\n",
    "global_last_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_time():\n",
    "    global global_time_list, global_last_time\n",
    "    global_time_list = []\n",
    "    global_last_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_time():\n",
    "    global global_last_time, global_time_list\n",
    "    new_time = time.perf_counter()\n",
    "    global_time_list.append(new_time - global_last_time)\n",
    "    global_last_time = time.perf_counter()\n",
    "    #print(\"step: %.2f\"%(global_time_list[-1]*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time():\n",
    "    \"\"\"Returns last interval records in millis.\"\"\"\n",
    "    global global_last_time, global_time_list\n",
    "    if global_time_list:\n",
    "        return 1000 * global_time_list[-1]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(a, b):\n",
    "    \"\"\"Dot product function since TensorFlow doesn't have one.\"\"\"\n",
    "    return tf.reduce_sum(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose_func(s):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN(object):\n",
    "    def __init__(self, layers, optimizer, logger, X_f, ub, lb, nu):\n",
    "        # Descriptive Keras model [2, 20, …, 20, 1]\n",
    "        self.u_model = tf.keras.Sequential()\n",
    "        self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
    "#         self.u_model.add(tf.keras.layers.Lambda(lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
    "        for width in layers[1:]:\n",
    "            self.u_model.add(tf.keras.layers.Dense(\n",
    "              width, activation=tf.nn.tanh,\n",
    "              kernel_initializer='glorot_normal'))\n",
    "\n",
    "#         self.u_model.add(\n",
    "#             tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "#         )\n",
    "        \n",
    "        # Computing the sizes of weights/biases for future decomposition\n",
    "        self.sizes_w = []\n",
    "        self.sizes_b = []\n",
    "        for i, width in enumerate(layers):\n",
    "            if i != 1:\n",
    "                self.sizes_w.append(int(width * layers[1]))\n",
    "                self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
    "\n",
    "        self.nu = nu\n",
    "        self.optimizer = optimizer\n",
    "        self.logger = logger\n",
    "\n",
    "        self.dtype = tf.float32\n",
    "\n",
    "        # Separating the collocation coordinates\n",
    "        self.t_f = tf.convert_to_tensor(X_f, dtype=self.dtype)\n",
    "\n",
    "    # Defining custom loss\n",
    "    def __loss(self, u, u_pred):\n",
    "        f_pred = self.f_model()\n",
    "        return tf.reduce_sum(tf.square(u - u_pred)) # + tf.reduce_sum(tf.square(f_pred))\n",
    "\n",
    "    def __grad(self, X, u):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = self.__loss(u, self.u_model(X))\n",
    "        return loss_value, tape.gradient(loss_value, self.u_model.trainable_variables)\n",
    "\n",
    "    # The actual PINN\n",
    "    def f_model(self):\n",
    "        # Using the new GradientTape paradigm of TF2.0,\n",
    "        # which keeps track of operations to get the gradient at runtime\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Watching the input we’ll need later, t\n",
    "            tape.watch(self.t_f)\n",
    "            # Getting the prediction\n",
    "            u = self.u_model(self.t_f)\n",
    "            # Deriving INSIDE the tape (since we’ll need the t derivative of this later, u_tt)\n",
    "            u_t = tape.gradient(u, self.t_f)\n",
    "\n",
    "        # Getting the other derivatives\n",
    "        u_tt = tape.gradient(u_t, self.t_f)\n",
    "        \n",
    "        del tape\n",
    "        \n",
    "        # Buidling the PINNs\n",
    "        return u_tt + 10.*np.sin(u)\n",
    "\n",
    "    def get_weights(self):\n",
    "        w = []\n",
    "        for layer in self.u_model.layers[1:]:\n",
    "            weights_biases = layer.get_weights()\n",
    "            weights = weights_biases[0].flatten()\n",
    "            biases = weights_biases[1]\n",
    "            w.extend(weights)\n",
    "            w.extend(biases)\n",
    "        return tf.convert_to_tensor(w, dtype=self.dtype)\n",
    "\n",
    "    def set_weights(self, w):\n",
    "        for i, layer in enumerate(self.u_model.layers[1:]):\n",
    "            start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
    "            end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
    "            weights = w[start_weights:end_weights]\n",
    "            w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
    "            weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
    "            biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
    "            weights_biases = [weights, biases]\n",
    "            layer.set_weights(weights_biases)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.u_model.summary()\n",
    "\n",
    "    # The training function\n",
    "    def fit(self, X_u, u, tf_epochs=5000, nt_config=Struct()):\n",
    "        self.logger.log_train_start(self)\n",
    "\n",
    "        # Creating the tensors\n",
    "        X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
    "        u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
    "        self.logger.log_train_opt(\"Adam\")\n",
    "        for epoch in range(tf_epochs):\n",
    "            # Optimization step\n",
    "            loss_value, grads = self.__grad(X_u, u)\n",
    "#             print(loss_value)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.u_model.trainable_variables))\n",
    "            self.logger.log_train_epoch(epoch, loss_value)\n",
    "            if epoch == tf_epochs - 1:\n",
    "                final_loss.append(loss_value.numpy())\n",
    "            if epoch % 10 == 0:\n",
    "                plt.clf()\n",
    "                plt.scatter(X_u, u, marker='.')\n",
    "                plt.scatter(X_u, self.u_model(X_u), marker='.')\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "#                 plt.show()\n",
    "\n",
    "\n",
    "        def loss_and_flat_grad(w):\n",
    "            with tf.GradientTape() as tape:\n",
    "                self.set_weights(w)\n",
    "                loss_value = self.__loss(u, self.u_model(X_u))\n",
    "            grad = tape.gradient(loss_value, self.u_model.trainable_variables)\n",
    "            grad_flat = []\n",
    "            for g in grad:\n",
    "                grad_flat.append(tf.reshape(g, [-1]))\n",
    "            grad_flat =  tf.concat(grad_flat, 0)\n",
    "            return loss_value, grad_flat\n",
    "\n",
    "\n",
    "        self.logger.log_train_end(tf_epochs)\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        u_star = self.u_model(X_star)\n",
    "        f_star = self.f_model()\n",
    "        return u_star, f_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Training and plotting the results'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## Training and plotting the results\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the model and training\n",
    "# logger = Logger(frequency=10)\n",
    "# # x, t, Exact_u, X_star, u_star, X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
    "# X_f, Exact_u, X_u_train, u_train, lb, ub = prep_data(N_u, N_f, noise=noise)\n",
    "# # plt.plot(Exact_u, \".\")\n",
    "# print(X_u_train.shape, u_train.shape)\n",
    "# plt.scatter(X_u_train, u_train, marker='.')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Training finished (epoch 5000): duration = 02:41  error = 1.3937e+00  \n",
      "For the [1, 80, 80, 80, 1] layer data: \n",
      "Average loss: 14.214595794677734\n",
      "Average time: 150.07133333333334\n",
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_loss = []\n",
    "\n",
    "# list of average loss for each layer\n",
    "layer_avg_loss = []\n",
    "layer_avg_time = []\n",
    "\n",
    "n_times = 3\n",
    "for layers in list_of_layers:\n",
    "    final_loss = []\n",
    "    average_time = []\n",
    "    for i in range(n_times):\n",
    "        # Creating the model and training\n",
    "        logger = Logger(frequency=10)\n",
    "        # x, t, Exact_u, X_star, u_star, X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
    "        X_f, Exact_u, X_u_train, u_train, lb, ub = prep_data(N_u, N_f, noise=noise)\n",
    "\n",
    "        pinn = PhysicsInformedNN(layers, tf_optimizer, logger, X_u_train, ub, lb, nu=OMEGA**2)\n",
    "        def error():\n",
    "            u_pred, _ = pinn.predict(X_f)\n",
    "            return np.linalg.norm(Exact_u - u_pred, 2) / np.linalg.norm(Exact_u, 2)\n",
    "        logger.set_error_fn(error)\n",
    "        pinn.fit(X_u_train, u_train, tf_epochs)\n",
    "        final_time = round(logger.log_time(), 3)\n",
    "        average_time.append(final_time)\n",
    "\n",
    "        # Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
    "        u_pred, f_pred = pinn.predict(X_f)\n",
    "        plt.figure(figsize=(10,7))\n",
    "        plt.scatter(X_u_train, u_train, label=\"input\", marker='.')\n",
    "        plt.scatter(X_f[:N_u], u_pred[:N_u], label=\"predicted\", marker='.')\n",
    "        plt.title(f\"Data vs Predicted\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        plt.savefig(f\"./data/layers{layers}_{N_u}DataPoints_loss{str(round(final_loss[-1],3))}_time{final_time}_epoch{tf_epochs}_lr{lr}_beta{beta1}_eps{eps}_noise{noise}.jpg\", dpi=300)\n",
    "        # plt.show()\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    layer_avg_loss.append(np.average(final_loss))\n",
    "    layer_avg_time.append(np.average(average_time))\n",
    "    \n",
    "for i in range(len(list_of_layers)):\n",
    "    print(f\"For the {list_of_layers[i]} layer data: \")\n",
    "    print(f\"Average loss: {layer_avg_loss[i]}\")\n",
    "    print(f\"Average time: {layer_avg_time[i]}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pinn = PhysicsInformedNN(layers, tf_optimizer, logger, X_u_train, ub, lb, nu=OMEGA**2)\n",
    "# def error():\n",
    "#     u_pred, _ = pinn.predict(X_f)\n",
    "#     return np.linalg.norm(Exact_u - u_pred, 2) / np.linalg.norm(Exact_u, 2)\n",
    "# logger.set_error_fn(error)\n",
    "# pinn.fit(X_u_train, u_train, tf_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
    "# u_pred, f_pred = pinn.predict(X_f)\n",
    "# plt.scatter(X_u_train, u_train, label=\"input\", marker='.')\n",
    "# plt.scatter(X_f[:N_u], u_pred[:N_u], label=\"predicted\", marker='.')\n",
    "# plt.title(\"Data vs Predicted (4pi)\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.savefig(f\"./data/layers{layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot_inf_cont_results(X_star, u_pred.numpy().flatten(), X_u_train, u_train,\n",
    "#   Exact_u, X, T, x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "Rmd,ipynb",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
